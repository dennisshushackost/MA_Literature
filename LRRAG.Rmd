---
title: "Literature Review Graph based RAG"
output: pdf_document
date: "2024-09-16"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Literature Review Graph-Based RAG

This section summarizes different research papers which employ Graph-Based Retrieval-Augmented Generation (RAG) and normal RAG approaches.

### Paper 1: [KG-RAG](https://arxiv.org/pdf/2405.12035)

This paper introduces a novel framework (KG-RAG) that aims to enhance the reasoning abilities of LLMs by integrating them with Knowledge Graphs (KGs). This integration addresses significant challenges faced by LLM-agents:

-   Information hallucination, catastrophic forgetting & limitation in processing extended contexts for knowledge intensive tasks.

    ![](images/clipboard-3083307246.png){width="482"}

RAG systems primarily rely on similarity search for retrieval. This approach, however, falls short when handling more complex queries. The limitation lies in its inability to precisely focus on the most relevant information, which results in retrieving numerous text chunks. These chunks often contain excessive or insufficient data, leading to an overload of irrelevant information. KGs can extend this RAG system by incorporating a explicit and accurrate representation of entities and relationships, which are more accurate than retrieving information through vector similarity.

**Knowledge Graph:**

-   Knowledge Triplets: (entity) - [relationship] - (entity) (A basic unit of information in the graph)
    -   Triplet $t = (e,r,e')$, where $e$ is the entity, $r$ = the predicate relationship and $e'$ is the object entity.
    -   A Graph $G=\left\{t=\left(e, r, e^{\prime}\right) \text {, where } e, e^{\prime} \in E, r \in R\right\}$

**Knowledge Graph Question Answering (KGQA)\
**The idea of KGQA is to respond to questions with information from the KG. For complex queries, this requires the infromation retrieval (IR) of multiple triplets. We can use a multi-hop traversal path: $w_z=e_0 \xrightarrow{r_1} e_1 \xrightarrow{r_2^1} \ldots \xrightarrow{r_l} e_l$., which connects a series of entities via relationships. Given a natural question $q$ and a KG $G$ a function $f$ should predict an answer $a \in A_q$ based on knowledge from $G$ . The predicted answer $a^*$ is computed by **maximizing** the probability of possible answers across all relevant paths $w_z$. Formally:

$a^*=f(q, G)=\underset{a \in A}{\arg \max } \sum_z P\left(w_z \mid q, G\right) \cdot P\left(a \mid w_z\right)$

where $P\left(w_z \mid q, G\right)$ represents the model's ability to identify the most relevant paths $w_z$ given the question $q$ and the KG $G$, and $P\left(a \mid w_z\right)$ denotes the probability of generating the answer $a$ based on the path $w_z$.

**Few-Shot Learning:\
**Few Shot learning is used to help the LLM extract the triplets from the text chunks. In this approach examples are provided to the LLM to help the model. Given a text chunk $T$ the LM must identify the different triples $t=\left(e, r, e^{\prime}\right)$: $T \xrightarrow{L M}\left\{t_i\right\}_{i=1}^n$

**Retrieval:**

Given a question $q$ and a KG $G$ the retrieval problem is a search problem, where the objective is to find paths $w_z$ within the graph $G$.

**Core Components of KG-RAG:**

1.  Knowledge Graph Construction: This includes named entity recognition (NER) & Relationship Extraction (RE) to extract the needed triplets.
